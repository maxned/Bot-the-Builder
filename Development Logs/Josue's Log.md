# TUESDAY MAY 8
* read over an example of q-learning [online](http://amunategui.github.io/reinforcement-learning/)
*  created the notebook of the example with some added comments to visualize what is going on in the example.
*  read over some more of [q-learning](https://en.wikipedia.org/wiki/Q-learning)

# Thursday May 10
* reaserched more on q-learning in order foigure out the state space
* one possible solution to the state space is to use actions as the state


# Sunday May 13
* updated the Readme file to add the change in our project 
* added some videos which cover the overview of q-learning and waka
* added the markdown cheatsheet link for some of our team members to use


# Thursday May 24
* Researched on [KNN](http://scikit-learn.org/stable/modules/neighbors.html)
* Wrote the basic implementation of the KNN algorithm using one replay 
* I used the `train_test_split` function to split the data into a training set and a test set

# Sunday May 28 
* Created  a log file to keep track of what commits happen and a description of these commits. 

# Monday May 29
* Reviewed @Matthew's creation of the Tkinter GUI
* Researched methods of feeding information of mutiple K values with their probabilities of [winning](https://askubuntu.com/questions/973140/running-command-periodically-and-save-output-to-a-csv-file)

# Monday June 4
* have been able to package up data to a csv file in order to use in the GUI that Matthew made. 
* kept it in a notebook so that we can run more test such as different numbers of neighbors
* Our output CSV file will only contain the second  and the probability of winning
